Delta +1 and -1 Function Analysis
==================================
Comparing our GCC 2.6.3 (patched) output against original Daytona USA Saturn binary.
Compiled with: cc1 -quiet -O2 -m2 -mbsr

================================================================================
PART 1: DELTA = +1 FUNCTIONS (Our code 1 instruction LONGER)
================================================================================

--------------------------------------------------------------------------------
FUN_0600F870  (delta = +1, 21 ours vs 20 expected)
--------------------------------------------------------------------------------

C source:
  extern void func_060114AC();
  extern int func_06011094();
  extern short counter_0607887C;
  extern char flag_0607887F;
  int FUN_0600F870() {
      int result;
      short val;
      func_060114AC(0);
      result = func_06011094();
      val = counter_0607887C;
      counter_0607887C = val - 1;
      if ((short)(val - 1) <= 0) { flag_0607887F = 4; }
      return result;
  }

Expected (original binary):
  sts.l pr,@-r15             ; push PR
  mov.l ...,r3               ; load &func_060114AC
  jsr @r3                    ; call func_060114AC
  mov #0,r4                  ;   (delay slot) arg=0
  mov.l ...,r3               ; load &func_06011094
  jsr @r3                    ; call func_06011094
  nop                        ;   (delay slot)
  mov.l ...,r4               ; load &counter_0607887C
  mov.w @r4,r2               ; val = counter
  add #-1,r2                 ; val--
  mov.w r2,@r4               ; store back
  exts.w r2,r2               ; sign extend
  cmp/pl r2                  ; test > 0
  bt LabelSkip               ; skip if positive
  mov #4,r2                  ; r2 = 4
  mov.l ...,r3               ; load &flag_0607887F
  mov.b r2,@r3               ; store flag
  lds.l @r15+,pr             ; pop PR
  rts                        ; return
  nop                        ;   (delay slot = nop)

Our output:
  sts.l pr,@-r15             ; push PR
  bsr _func_060114AC         ; BSR direct call
  mov #0,r4                  ;   (delay slot) arg=0
  bsr _func_06011094         ; BSR direct call
  nop                        ;   (delay slot)
  mov r0,r2                  ; *** EXTRA: save return value ***
  mov.l L3,r1                ; load &counter_0607887C
  mov.w @r1,r0               ; val = counter
  add #-1,r0                 ; val--
  mov.w r0,@r1               ; store back
  exts.w r0,r0               ; sign extend
  cmp/pl r0                  ; test > 0
  bt.s L2                    ; skip if positive (delayed branch)
  mov #4,r0                  ;   (delay slot) r0=4
  mov.l L4,r1                ; load &flag_0607887F
  mov.b r0,@r1               ; store flag
  L2:
  lds.l @r15+,pr             ; pop PR
  rts                        ; return
  mov r2,r0                  ;   (delay slot) restore result

ANALYSIS:
  Opcode count: Expected=20, Ours=21, Delta=+1

  Root cause: REGISTER ALLOCATION / RETURN VALUE PRESERVATION

  The original binary uses jsr @r3 (indirect call through register), which lets
  r3 serve as the call target while r0 (return value) and other caller-saved
  registers are free for subsequent use. The original compiler was able to keep
  the return value in r0 throughout the rest of the function without needing a
  separate "save" instruction.

  Our compiler generates BSR (direct calls, which is correct and desired), but
  the register allocator decides it needs to preserve the return value of
  func_06011094() across the subsequent counter decrement operations. It emits:
    mov r0,r2     ; save func_06011094 return value
  and later:
    mov r2,r0     ; restore it in rts delay slot

  The original avoids this by using r4 (not r0) for the counter address, and
  using r2 for the counter value, so r0 stays free as the return value. Our
  compiler uses r0 for the counter operations (mov.w @r1,r0) which conflicts
  with preserving the function return value in r0.

  The bt.s (delayed branch) vs bt (non-delayed) is also a minor scheduling
  difference but doesn't change the count -- the original has 20 instructions
  including the nop in the rts delay slot, while we have 21 but fill the rts
  delay slot usefully.

  PATTERN: Register allocation conflict -- GCC uses r0 for mov.w loads
  (SH arch requires r0 for @(disp,Rn) addressing) which forces a save/restore
  of the call return value. Original compiler avoided r0 for intermediate work.

  FIXABILITY: Very difficult. Would require teaching the register allocator to
  avoid r0 for intermediate values when it's holding a return result. This is
  a fundamental register allocator issue, not a peephole-fixable pattern.

--------------------------------------------------------------------------------
FUN_06027344  (delta = +1, 10 ours vs 9 expected)
--------------------------------------------------------------------------------

C source:
  int FUN_06027344(param_1) int param_1; {
    return *(int *)(0x002F2F20 + (((unsigned int)(param_1 + 0x4000) >> 2) + 2 & 0x3FFC));
  }

Expected (original binary @ 06027344):
  mov.w @(PC),r0             ; r0 = 0x4000
  add r0,r4                  ; r4 = param_1 + 0x4000
  mov.w @(PC),r0             ; r0 = 0x3FFC (mask)
  shlr2 r4                   ; r4 >>= 2
  add #2,r4                  ; r4 += 2
  and r0,r4                  ; r4 &= 0x3FFC
  mov.l @(PC),r0             ; r0 = 0x002F2F20 (base)
  rts                        ; return
  mov.l @(r0,r4),r0          ;   (delay slot) r0 = *(r0+r4) -- INDEXED LOAD

Our output:
  mov.w L2,r0                ; r0 = 0x4000
  add r0,r4                  ; r4 = param_1 + 0x4000
  shlr2 r4                   ; r4 >>= 2
  add #2,r4                  ; r4 += 2
  mov.w L3,r0                ; r0 = 0x3FFC (mask)
  and r0,r4                  ; r4 &= 0x3FFC
  mov.l L4,r0                ; r0 = 0x002F2F20 (base)
  add r0,r4                  ; *** EXTRA: r4 = base + offset ***
  rts                        ; return
  mov.l @r4,r0               ;   (delay slot) r0 = *r4 -- SIMPLE LOAD

ANALYSIS:
  Opcode count: Expected=9, Ours=10, Delta=+1

  Root cause: MISSING INDEXED ADDRESSING MODE (mov.l @(r0,r4),r0)

  The original binary uses `mov.l @(r0,r4),r0` in the rts delay slot. This is
  an indexed load: it adds r0+r4 to form the address and loads 4 bytes into r0,
  all in a single instruction.

  Our GCC emits:
    add r0,r4          ; compute base+offset in r4
    mov.l @r4,r0       ; then load from r4
  This is 2 instructions instead of 1.

  GCC 2.6.3's SH backend does not generate indexed addressing modes
  (mov.l @(Rm,Rn),Rd) in this context. The RTL pattern for indexed loads exists
  in the machine description but the combiner/register allocator doesn't produce
  it when one operand is a constant pool load.

  PATTERN: Missing indexed addressing mode `mov.l @(r0,Rn),Rm`
  This same pattern appears in FUN_06027348 and FUN_06027358.

  FIXABILITY: Moderate. Could potentially add a peephole2 pattern that combines:
    add rA,rB / mov.l @rB,rC  -->  mov.l @(rA,rB),rC
  when the add result is dead after the load. However, this is tricky because
  (1) the add clobbers rB which may still be needed, and (2) the indexed form
  @(Rm,Rn) on SH-2 is limited (only certain register combinations work).
  A post-pass peephole (like the dt peephole) would be more feasible.

--------------------------------------------------------------------------------
FUN_06027348  (delta = +1, 8 ours vs 7 expected)
--------------------------------------------------------------------------------

C source:
  int FUN_06027348(param_1) unsigned int param_1; {
    return *(int *)(0x002F2F20 + ((param_1 >> 2) + 2 & 0x3FFC));
  }

Expected (original binary @ 06027348):
  mov.w @(PC),r0             ; r0 = 0x3FFC (mask)
  shlr2 r4                   ; r4 >>= 2
  add #2,r4                  ; r4 += 2
  and r0,r4                  ; r4 &= 0x3FFC
  mov.l @(PC),r0             ; r0 = 0x002F2F20 (base)
  rts                        ; return
  mov.l @(r0,r4),r0          ;   (delay slot) INDEXED LOAD

Our output:
  shlr2 r4                   ; r4 >>= 2
  add #2,r4                  ; r4 += 2
  mov.w L2,r0                ; r0 = 0x3FFC (mask)
  and r0,r4                  ; r4 &= 0x3FFC
  mov.l L3,r0                ; r0 = 0x002F2F20 (base)
  add r0,r4                  ; *** EXTRA: r4 = base + offset ***
  rts                        ; return
  mov.l @r4,r0               ;   (delay slot) SIMPLE LOAD

ANALYSIS:
  Opcode count: Expected=7, Ours=8, Delta=+1

  Root cause: MISSING INDEXED ADDRESSING MODE (same as FUN_06027344)

  Identical pattern: original uses `mov.l @(r0,r4),r0` in rts delay slot,
  combining the add+load into one instruction. Our GCC emits separate
  `add r0,r4` + `mov.l @r4,r0`.

  PATTERN: Missing indexed addressing mode `mov.l @(r0,Rn),Rm`
  FIXABILITY: Same as FUN_06027344 -- post-pass peephole.

--------------------------------------------------------------------------------
FUN_06027358  (delta = +1, 16 ours vs 15 expected)
--------------------------------------------------------------------------------

C source:
  void FUN_06027358(param_1, param_2, param_3)
      int param_1; int *param_2; int *param_3;
  {
    char *puVar1 = 0x002F2F20;
    int iVar3 = 0x4000;
    unsigned int uVar2 = 0x3FFC;
    *param_2 = *(int *)(0x002F2F20 + (param_1 + 8U >> 2 & uVar2));
    *param_3 = *(int *)(puVar1 + (iVar3 + param_1 + 8U >> 2 & uVar2));
  }

Expected (original binary @ 06027358):
  mov.w @(PC),r3             ; r3 = 0x4000 (+ 8 combined)
  add #8,r4                  ; param_1 + 8
  mov.w @(PC),r1             ; r1 = 0x3FFC (mask)
  add r4,r3                  ; r3 = (param_1+8) + 0x4000
  mov.l @(PC),r0             ; r0 = 0x002F2F20 (base)
  shlr2 r4                   ; r4 >>= 2  (first index)
  and r1,r4                  ; r4 &= 0x3FFC
  shlr2 r3                   ; r3 >>= 2  (second index)
  mov.l @(r0,r4),r2          ; *** INDEXED LOAD #1 ***
  and r1,r3                  ; r3 &= 0x3FFC
  mov.l r2,@r5               ; *param_2 = first value
  nop
  mov.l @(r0,r3),r1          ; *** INDEXED LOAD #2 ***
  rts                        ; return
  mov.l r1,@r6               ;   (delay slot) *param_3 = second value

Our output:
  mov.l L2,r2                ; r2 = 0x002F2F20 (base)
  mov.w L3,r1                ; r1 = 0x3FFC (mask)
  mov r4,r0                  ; r0 = param_1
  add #8,r0                  ; r0 = param_1 + 8
  shlr2 r0                   ; r0 >>= 2
  and r1,r0                  ; r0 &= 0x3FFC
  mov.l @(r0,r2),r0          ; INDEXED LOAD (GCC DID generate this one!)
  mov.l r0,@r5               ; *param_2 = first value
  mov.w L4,r0                ; r0 = 0x4008 (0x4000+8)
  add r0,r4                  ; r4 = param_1 + 0x4008
  shlr2 r4                   ; r4 >>= 2
  mov r4,r0                  ; *** EXTRA: mov r4,r0 ***
  and r1,r0                  ; r0 &= 0x3FFC (needs r0 for and?)
  mov.l @(r0,r2),r2          ; INDEXED LOAD #2
  rts                        ; return
  mov.l r2,@r6               ;   (delay slot) *param_3 = second value

ANALYSIS:
  Opcode count: Expected=15, Ours=16, Delta=+1

  Root cause: UNNECESSARY REGISTER COPY (mov r4,r0)

  Interestingly, our GCC DOES generate `mov.l @(r0,r2),r0` indexed loads here!
  So the indexed addressing mode IS available in some contexts.

  The extra instruction is `mov r4,r0` at line 12 of our output. After computing
  r4 = param_1 + 0x4008 and shlr2 r4, the compiler moves r4 to r0 before the
  AND instruction. This is because on SH-2, `and Rm,Rn` works with any register
  pair, so the mov is unnecessary -- the compiler could have done `and r1,r4`
  directly, then used `mov.l @(r4,r2),...`.

  The original binary does exactly that: it keeps the index in r3 throughout,
  does `and r1,r3`, then `mov.l @(r0,r3),r1`.

  PATTERN: Unnecessary register copy before AND -- register allocator routes
  the value through r0 when it doesn't need to.

  FIXABILITY: Difficult. This is a register allocator quality issue. The compiler
  is constrained by its internal register preference rules.

--------------------------------------------------------------------------------
FUN_0601AB8C  (delta = +1, 30 ours vs 29 expected)
--------------------------------------------------------------------------------

C source: (complex expression with memory loads, shifts, byte extraction)

Expected (original binary @ 0601AB8C):
  mov.l ...,r4               ; r4 = &0x0607EAD8
  mov.l ...,r2               ; r2 = &0x0605DE40
  mov.l @r4,r0               ; r0 = *r4
  exts.b r0,r0               ; sign-extend byte
  mov r0,r3                  ; r3 = r0
  shll2 r0                   ; r0 <<= 2  (r0 * 4)
  shll2 r3                   ; r3 <<= 2
  shll r3                    ; r3 <<= 1  (r3 * 8)
  add r3,r0                  ; r0 = byte*4 + byte*8 = byte*12
  exts.b r0,r0               ; sign-extend result
  mov.l ...,r3               ; r3 = &0x0605AD00
  add r2,r0                  ; r0 += table_base
  mov.l @r3,r3               ; r3 = *0x0605AD00
  shll2 r3                   ; r3 <<= 2
  mov.l @(r0,r3),r1          ; *** INDEXED LOAD: r1 = *(r0 + r3) ***
  mov.l ...,r3               ; r3 = &0x06086004
  mov.l r1,@r3               ; store result
  mov.l @r4,r0               ; reload *0x0607EAD8
  mov.l ...,r3               ; r3 = &0x0607EAE0
  mov.l ...,r2               ; r2 = &0x0605DE24
  shll r0                    ; r0 <<= 1
  mov.l @r3,r3               ; r3 = *0x0607EAE0
  add r3,r0                  ; r0 += r3
  shll2 r0                   ; r0 <<= 2
  mov.l @(r0,r2),r4          ; *** INDEXED LOAD: r4 = *(r0 + r2) ***
  mov.l @(4,r4),r1           ; r1 = *(r4 + 4)
  mov.l ...,r0               ; r0 = &0x06086008
  rts
  mov.l r1,@r0               ; (delay slot) store result

Our output:
  mov.l L2,r3                ; r3 = 0x0607EAD8
  mov.l L3,r7                ; r7 = 0x06086004 (dest addr loaded early)
  mov.l L4,r0                ; r0 = &0x0605AD00
  mov.l @r0,r2               ; r2 = *0x0605AD00
  shll2 r2                   ; r2 <<= 2
  mov r3,r0
  add #3,r0                  ; r0 = 0x0607EADB (addr + 3 = byte offset)
  mov.b @r0,r1               ; *** r1 = byte at addr+3 ***
  mov r1,r0                  ; r0 = byte
  add r1,r0                  ; r0 = byte*2
  add r1,r0                  ; r0 = byte*3
  shll2 r0                   ; r0 = byte*12
  exts.b r0,r0               ; sign extend
  add r2,r0                  ; r0 += shifted table index
  mov.l L5,r1                ; r1 = &0x0605DE40
  mov.l @(r0,r1),r0          ; INDEXED LOAD (works!)
  mov.l r0,@r7               ; store to 0x06086004
  mov.l L6,r2                ; r2 = &0x06086008
  mov.l @r3,r0               ; r0 = *0x0607EAD8
  add r0,r0                  ; r0 <<= 1 (shll)
  mov.l L7,r1                ; r1 = &0x0607EAE0
  mov.l @r1,r1               ; r1 = *0x0607EAE0
  add r1,r0                  ; r0 += r1
  mov.l L8,r1                ; r1 = &0x0605DE24
  add r1,r0                  ; *** EXTRA: add base to offset ***
  shll2 r0                   ; r0 <<= 2
  mov.l @r0,r0               ; SIMPLE LOAD (not indexed!)
  mov.l @(4,r0),r0           ; *(r0 + 4)
  rts
  mov.l r0,@r2               ; store to 0x06086008

ANALYSIS:
  Opcode count: Expected=29, Ours=30, Delta=+1

  Root cause: MIXED -- two differences that net to +1:

  1. BYTE ACCESS APPROACH (different, nets to +0):
     Original: mov.l @r4,r0 / exts.b r0,r0 (load word, sign-extend byte)
     Ours: add #3,r0 / mov.b @r0,r1 (compute byte address, load byte directly)
     Then for *12: Original uses mov r0,r3 / shll2 r0 / shll2 r3 / shll r3 / add r3,r0
                   Ours uses mov r1,r0 / add r1,r0 / add r1,r0 / shll2 r0
     These are different approaches but same instruction count for this part.

  2. SECOND INDEXED LOAD MISSING (+1):
     Original: mov.l @(r0,r2),r4  -- indexed load combining base + offset
     Ours: add r1,r0 / mov.l @r0,r0 -- separate add then simple load

     The original uses `mov.l @(r0,r2),r4` for the second table lookup,
     combining the 0x0605DE24 base address with the computed index in one
     instruction. Our compiler separates this into `add r1,r0` + `mov.l @r0,r0`.

  PATTERN: Missing indexed addressing mode for second load (same pattern as
  FUN_06027344/FUN_06027348). First load in the function DOES use indexed mode.

  FIXABILITY: Same as FUN_06027344 -- the indexed mode works sometimes (first
  load) but the compiler fails to use it in other contexts. A peephole could
  potentially catch the `add rA,rB / mov.l @rB,rC` pattern.

================================================================================
PART 2: DELTA = -1 FUNCTIONS (Our code 1 instruction SHORTER)
================================================================================

--------------------------------------------------------------------------------
FUN_060054EA  (delta = -1, 11 ours vs 12 expected)
--------------------------------------------------------------------------------

Expected (original binary):
  mov.l ...,r3               ; r3 = &0x06063E04
  mov.l r4,@r3               ; store param_1
  mov #0,r4                  ; r4 = 0
  mov.l ...,r3               ; r3 = &0x06063E08
  mov.w r4,@r3               ; store 0 as short
  mov.l ...,r3               ; r3 = &0x06063F08
  mov.l r4,@r3               ; store 0 as int
  mov r3,r1                  ; r1 = r3 (copy &0x06063F08)
  mov.l @r1,r1               ; r1 = *0x06063F08 (=0, just stored)
  mov.l ...,r3               ; r3 = &0x06063F04
  rts
  mov.l r1,@r3               ; store to 0x06063F04

Our output:
  mov.l L2,r0                ; r0 = &0x06063E04
  mov.l r4,@r0               ; store param_1
  mov.l L3,r0                ; r0 = &0x06063E08
  mov #0,r1                  ; r1 = 0
  mov.w r1,@r0               ; store 0 as short
  mov.l L4,r0                ; r0 = &0x06063F08
  mov #0,r1                  ; r1 = 0  (redundant but counted)
  mov.l r1,@r0               ; store 0 as int
  mov.l L5,r0                ; r0 = &0x06063F04
  rts
  mov.l r1,@r0               ; store 0 (r1 still = 0)

ANALYSIS:
  Opcode count: Expected=12, Ours=11, Delta=-1 (we are SHORTER)

  The original does:
    mov.l r4,@r3       ; store 0 to 0x06063F08
    mov r3,r1          ; copy address
    mov.l @r1,r1       ; reload the zero we just stored
    mov.l ...,r3
    mov.l r1,@r3       ; store it to 0x06063F04

  This is 2 extra instructions (copy addr + reload) to accomplish what should
  be just storing 0 again. Our compiler recognizes that after storing 0 to
  0x06063F08, the value 0 is still in r1, so it can store r1 directly to
  0x06063F04 without reloading.

  WHY ORIGINAL IS LONGER: The C source has `*(int *)0x06063F04 = *(int *)puVar1`
  where puVar1 = 0x06063F08. The original compiler literally reads from 0x06063F08
  (which was just zeroed) instead of reusing the zero constant. Our compiler's
  CSE (common subexpression elimination) or constant propagation realizes the
  value is known to be 0.

  VERDICT: Our code is CORRECT and more optimal. The original compiler missed
  the optimization.

--------------------------------------------------------------------------------
FUN_0600DE40  (delta = -1, 9 ours vs 10 expected)
--------------------------------------------------------------------------------

Expected (original binary):
  sts.l pr,@-r15
  mov.l ...,r3               ; &0x0607EA98
  mov.l ...,r2               ; &0x060786CA
  mov.l @r3,r3               ; load value
  shar r3                    ; >> 1 (arithmetic)
  mov.w r3,@r2               ; store short
  bsr FUN_0600e410
  nop
  bra FUN_0600e0c0           ; tail call
  lds.l @r15+,pr

Our output:
  sts.l pr,@-r15
  mov.l L2,r1                ; &0x060786CA
  mov.l L3,r0                ; &0x0607EA98
  mov.l @r0,r0               ; load value
  shar r0                    ; >> 1
  bsr _FUN_0600e410          ; BSR (fills delay slot with mov.w!)
  mov.w r0,@r1               ;   (delay slot) store short
  bra _FUN_0600e0c0          ; tail call
  lds.l @r15+,pr

ANALYSIS:
  Opcode count: Expected=10, Ours=9, Delta=-1 (we are SHORTER)

  The original has a `nop` in the bsr delay slot. Our compiler successfully
  fills the bsr delay slot with `mov.w r0,@r1` (the store instruction), which
  the original compiler left as a nop.

  WHY ORIGINAL IS LONGER: The original compiler didn't fill the bsr delay slot.
  Our GCC's delayed-branch scheduler found that `mov.w r0,@r1` can be moved
  into the delay slot because it has no data dependency on the bsr target.

  VERDICT: Our code is CORRECT and more optimal. Better delay slot filling.

--------------------------------------------------------------------------------
FUN_0600DE54  (delta = -1, 13 ours vs 14 expected)
--------------------------------------------------------------------------------

Expected (original binary):
  sts.l pr,@-r15
  mov.l ...,r3               ; &0x0607EA98
  mov.l ...,r2               ; &0x060786CA
  mov.l @r3,r3
  shar r3
  mov.w r3,@r2
  mov.l ...,r1               ; &0x0607E944
  mov.l ...,r2               ; &0x0607E940
  mov.l @r1,r1
  mov.l r1,@r2
  bsr FUN_0600e99c
  nop                        ; *** nop in delay slot ***
  bra FUN_0600e0c0
  lds.l @r15+,pr

Our output:
  sts.l pr,@-r15
  mov.l L2,r1                ; &0x060786CA
  mov.l L3,r0                ; &0x0607EA98
  mov.l @r0,r0
  shar r0
  mov.w r0,@r1
  mov.l L4,r1                ; &0x0607E940
  mov.l L5,r0                ; &0x0607E944
  mov.l @r0,r0
  bsr _FUN_0600e99c
  mov.l r0,@r1               ;   (delay slot) filled!
  bra _FUN_0600e0c0
  lds.l @r15+,pr

ANALYSIS:
  Same pattern as FUN_0600DE40. Original has nop in bsr delay slot; our compiler
  fills it with the mov.l store instruction.

  VERDICT: Our code is CORRECT and more optimal.

--------------------------------------------------------------------------------
FUN_060149CC  (delta = -1, 9 ours vs 10 expected)
--------------------------------------------------------------------------------

Expected (original binary):
  mov.l ...,r3               ; r3 = 0x00008000 (OR mask)
  mov.l ...,r2               ; r2 = &0x060A3D88
  mov.w @r2,r2               ; load short
  or r3,r2                   ; set bit 15
  mov.l ...,r3               ; r3 = &0x060A3D88 (RELOAD same address!)
  mov.w r2,@r3               ; store back
  mov #1,r2
  mov.l ...,r3               ; r3 = &0x060635AC
  rts
  mov.w r2,@r3               ; store 1

Our output:
  mov.l L2,r2                ; r2 = &0x060A3D88
  mov.w L3,r1                ; r1 = 0x8000 (-32768 as short)
  mov.w @r2,r0               ; load short
  or r1,r0                   ; set bit 15
  mov.w r0,@r2               ; store back (REUSES r2!)
  mov.l L4,r0                ; r0 = &0x060635AC
  mov #1,r1
  rts
  mov.w r1,@r0

ANALYSIS:
  Opcode count: Expected=10, Ours=9, Delta=-1 (we are SHORTER)

  The original loads &0x060A3D88 TWICE -- once to read (mov.w @r2,r2 destroys
  the address!) and once to write back. Our compiler keeps the address in r2,
  loads into r0, ORs, and stores back through r2 -- avoiding the redundant
  address reload.

  Original: mov.l addr,r2 / mov.w @r2,r2 (destroys r2!) / ... / mov.l addr,r3
  Ours:     mov.l addr,r2 / mov.w @r2,r0 (preserves r2!) / ... / mov.w r0,@r2

  WHY ORIGINAL IS LONGER: The original compiler's read-modify-write sequence
  destroys the address register, requiring a reload. Our GCC uses a separate
  register for the loaded value, preserving the address.

  VERDICT: Our code is CORRECT and more optimal. Better register allocation
  for read-modify-write patterns.

--------------------------------------------------------------------------------
FUN_060149E0  (delta = -1, 9 ours vs 10 expected)
--------------------------------------------------------------------------------

Expected (original binary):
  mov.w @(PC),r3             ; r3 = 0x7FFF (AND mask)
  mov.l ...,r2               ; r2 = &0x060A3D88
  mov.w @r2,r2               ; load short (destroys address!)
  and r3,r2                  ; clear bit 15
  mov.l ...,r3               ; r3 = &0x060A3D88 (RELOAD!)
  mov.w r2,@r3               ; store back
  mov #1,r2
  mov.l ...,r3               ; r3 = &0x060635AC
  rts
  mov.w r2,@r3

Our output:
  mov.l L2,r2                ; r2 = &0x060A3D88
  mov.w L3,r1                ; r1 = 0x7FFF
  mov.w @r2,r0               ; load (preserves r2!)
  and r1,r0                  ; clear bit 15
  mov.w r0,@r2               ; store back
  mov.l L4,r0                ; &0x060635AC
  mov #1,r1
  rts
  mov.w r1,@r0

ANALYSIS:
  Identical to FUN_060149CC -- same read-modify-write address clobbering pattern
  in the original. Our compiler avoids the redundant address reload.

  VERDICT: Our code is CORRECT and more optimal.

--------------------------------------------------------------------------------
FUN_060192B4  (delta = -1, 11 ours vs 11 expected -- WAIT, checking...)
--------------------------------------------------------------------------------

Expected (original binary):
  mov #0,r5                  ; r5 = 0
  mov.l ...,r6               ; r6 = 0x25A00000 (dest ptr)
  mov.l ...,r4               ; r4 = 0x0007FFFF (counter)
  Loop:
  mov r6,r3                  ; r3 = current ptr
  exts.b r5,r2               ; r2 = sign-extend byte (0)
  add #1,r6                  ; advance ptr
  dt r4                      ; decrement and test counter
  bf/s Loop                  ; loop if not zero
  mov.b r2,@r3               ; (delay slot) store byte
  rts
  nop

Our output:
  mov.l L6,r1                ; r1 = 0x0007FFFF (counter)
  mov.l L7,r0                ; r0 = 0x25A00000 (dest ptr)
  mov #0,r2                  ; r2 = 0
  Loop:
  add #-1,r1                 ; counter--
  mov.b r2,@r0               ; store byte
  tst r1,r1                  ; test counter == 0
  bf.s Loop                  ; loop if not zero
  add #1,r0                  ; (delay slot) advance ptr
  rts
  nop

ANALYSIS:
  Opcode count: Expected=11, Ours=10, Delta=-1 (we are SHORTER)

  The original has extra instructions in the loop body:
    mov r6,r3                ; copy pointer (3 regs for what needs 1)
    exts.b r5,r2             ; sign-extend 0 to 0 (pointless!)

  Our compiler avoids these unnecessary copies:
  - It stores directly through r0 (no copy to r3)
  - It uses r2=0 directly (no exts.b of zero)

  However, our compiler doesn't use the `dt` instruction (despite having the
  dt peephole). This is because the peephole matches `add #-1,rN / tst rN,rN`
  which produces `dt rN` -- but wait, looking at the output it shows separate
  `add #-1,r1` + `tst r1,r1` instead of `dt r1`. This suggests the dt peephole
  didn't fire here, possibly because of the intervening `mov.b r2,@r0` between
  the add and tst.

  Actually, re-reading the harness: the test harness counts opcode NAMES not
  full instructions. Let me recount:
  Expected: mov, mov.l, mov.l, mov, exts.b, add, dt, bf/s, mov.b, rts, nop = 11
  Ours: mov.l, mov.l, mov, add, mov.b, tst, bf.s, add, rts, nop = 10

  Yes, delta=-1. Our loop body is 5 insns (add/mov.b/tst/bf.s/add) vs
  original's 6 insns (mov/exts.b/add/dt/bf.s/mov.b). Even without dt, we save
  2 insns in the loop (no mov r6,r3, no exts.b) but lose 1 (tst instead of dt).
  Net: -1 per iteration, and the setup is also 1 insn shorter (3 vs 3, same).

  NOTE: The dt peephole doesn't fire because the `add #-1` and `tst` are
  separated by `mov.b r2,@r0`. The peephole requires them to be adjacent.

  VERDICT: Our code is CORRECT. We're shorter due to avoiding redundant register
  copies, but ideally we'd also use `dt` for a total of -2.

--------------------------------------------------------------------------------
FUN_0602755C  (delta = -1, 9 ours vs 10 expected)
--------------------------------------------------------------------------------

Expected (original binary):
  mov.w @(PC),r2             ; r2 = 0xFFFFFF00 (-256)
  mov r4,r3                  ; r3 = param_1
  mov.l r5,@(0,r2)           ; *0xFFFFFF00 = param_2
  shlr16 r3                  ; r3 >>= 16
  exts.w r3,r3               ; sign extend word
  mov.l r3,@(16,r2)          ; *(base+16) = sign-extended high half
  shll16 r4                  ; r4 <<= 16
  mov.l r4,@(20,r2)          ; *(base+20) = shifted low half
  rts
  mov.l @(28,r2),r0          ; (delay slot) return *(base+28)

Our output:
  mov.w L2,r0                ; r0 = 0xFF00 (-256 as short, sign-extended)
  mov.l r5,@r0               ; *0xFFFFFF00 = param_2
  swap.w r4,r1               ; r1 = param_1 with halfwords swapped
  exts.w r1,r1               ; sign extend (gets upper 16 bits, sign-extended)
  mov.l r1,@(16,r0)          ; *(base+16) = sign-extended high half
  shll16 r4                  ; r4 <<= 16
  mov.l r4,@(20,r0)          ; *(base+20) = shifted low half
  rts
  mov.l @(28,r0),r0          ; (delay slot) return *(base+28)

ANALYSIS:
  Opcode count: Expected=10, Ours=9, Delta=-1 (we are SHORTER)

  The key difference: the original uses `mov r4,r3` to copy param_1 before
  shifting, because `shlr16` is destructive. Our compiler uses `swap.w r4,r1`
  which both copies AND does a 16-bit halfword swap in one instruction, avoiding
  the separate `mov r4,r3` + `shlr16 r3` (2 insns) with `swap.w r4,r1` (1 insn).

  Original: mov r4,r3 / shlr16 r3    = 2 instructions to get upper halfword
  Ours:     swap.w r4,r1             = 1 instruction (swap halves of r4 into r1)

  The swap.w puts the upper 16 bits into the lower 16 bits of r1, which after
  exts.w gives the same sign-extended result.

  VERDICT: Our code is CORRECT and more optimal. GCC uses swap.w instruction
  which the original compiler didn't.

================================================================================
PART 3: SUMMARY
================================================================================

DELTA = +1 ROOT CAUSES:
  Pattern A: Missing indexed addressing mode (mov.l @(Rm,Rn),Rd)
    - FUN_06027344: add r0,r4 / mov.l @r4,r0  -->  should be mov.l @(r0,r4),r0
    - FUN_06027348: add r0,r4 / mov.l @r4,r0  -->  should be mov.l @(r0,r4),r0
    - FUN_0601AB8C: add r1,r0 / mov.l @r0,r0  -->  should be mov.l @(r1,r0),r0
    (3 functions, same pattern)

  Pattern B: Register allocation forces extra copy
    - FUN_0600F870: mov r0,r2 to save return value, then mov r2,r0 to restore
    - FUN_06027358: mov r4,r0 before AND (unnecessary copy)
    - FUN_0601AB8C: (also contributes, mixed with Pattern A)
    (2-3 functions)

  Most promising fix: A post-pass peephole for Pattern A:
    add rA,rB / mov.{l,w,b} @rB,rC  -->  mov.{l,w,b} @(rA,rB),rC
  when rB is dead after the load. This would fix 3-4 of the 5 delta=+1 functions.

DELTA = -1 ROOT CAUSES (why WE are shorter):
  - Better delay slot filling (FUN_0600DE40, FUN_0600DE54): nop -> useful insn
  - Better register allocation for read-modify-write (FUN_060149CC, FUN_060149E0):
    avoid clobbering address register
  - CSE / constant propagation (FUN_060054EA): avoid reloading known-zero value
  - Better instruction selection (FUN_0602755C): swap.w instead of mov+shlr16
  - Fewer redundant copies (FUN_060192B4): skip unnecessary mov/exts.b

  All delta=-1 cases are genuine optimizations where our GCC produces better
  code than the original binary. These are NOT bugs -- our output is correct.

POTENTIAL PEEPHOLE FOR INDEXED ADDRESSING:
  A new post-pass peephole (similar to the dt peephole) that scans for:
    add rA,rB
    mov.{l,w,b} @rB,rC
  and replaces with:
    mov.{l,w,b} @(rA,rB),rC
  provided:
    - rB is dead after the mov (its only use was as the address)
    - rA is still live or is rC (the output register)
    - The combination fits SH-2 indexed addressing constraints

  This would fix FUN_06027344, FUN_06027348, and the second load in FUN_0601AB8C.
  FUN_06027358's extra mov is a different issue (reg alloc copying before AND).
  FUN_0600F870's extra insn is a deep register allocator issue (r0 conflict).
