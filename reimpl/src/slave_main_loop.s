/* slave_main_loop -- L3 assembly (SH-2 mnemonics)
 * Translation unit: 0x06034F08 - 0x06035A08
 * Auto-generated by tools/generate_l3_tu.py
 *
 * Secondary SH-2 main loop and soft-float / utility library.
 *
 * slave_main_loop    — polls ICF bit, dispatches callback, loops forever
 * sym_06034F78       — bitfield insert (mask & OR into 32-bit word)
 * sym_06034FE0       — free-timer register config (FRT)
 * sym_06034FFC       — signed 32-bit divide  (r1 / r0 → r0)
 * sym_060350B0       — unsigned 32-bit divide (r1:r0 / r0 → remainder in r0)
 * sym_06035168       — longword memcpy with unrolled jump table (0-16 longs)
 * sym_06035228       — byte memcpy (r0 bytes from @r2 to @r1)
 * sym_06035280       — logical shift left by n
 * sym_06035340       — arithmetic shift right by n
 * sym_06035438       — integer absolute value
 * sym_06035460       — double-precision IEEE 754 add
 * sym_060357B8       — double-precision float → 32-bit integer
 * sym_06035844       — double-precision IEEE 754 subtract
 * sym_060358EC       — 32-bit integer → double-precision float
 * sym_060359E4       — double-precision IEEE 754 multiply (partial)
 * DAT_06035734       — power-of-2 bitmask table (32 entries x2)
 */

    .section .text.FUN_06034F08


    .global slave_main_loop
    .type slave_main_loop, @function
slave_main_loop:
    sts.l pr, @-r15                 ! save return address
    add #-0x8, r15                  ! allocate 8 bytes on stack
    mov #0x1, r3
    mov.l r3, @(4, r15)            ! local[1] = 0x1
    mov #0x0, r3
    mov.l r3, @r15                  ! local[0] = 0x0
    stc sr, r0                      ! read status register
    mov.w   .L_mask_sr_imask, r3    ! r3 = 0xFF0F — clear I3..I0 bits
    and r3, r0                      ! mask out interrupt level
    or #0xF0, r0                    ! set I3..I0 = 0xF (level 15 = all masked)
    ldc r0, sr                      ! disable all interrupts
    mov #0x0, r2
    mov.w   .L_reg_tier, r3        ! r3 → FRT TIER (0xFFFFFEE2)
    mov.w r2, @r3                   ! TIER = 0 — disable timer interrupts
    mov #0x0, r2
    mov.w   .L_reg_iprb, r3        ! r3 → IPRB (0xFFFFFE60)
    mov.w r2, @r3                   ! IPRB = 0 — clear FRT interrupt priority
    mov #0x1, r2
    mov.w   .L_reg_tier_byte, r3   ! r3 → TIER byte (0xFFFFFE10)
    mov.b r2, @r3                   ! TIER.ICIE = 1 — enable input capture IRQ
    bra     .L_loop_top
    nop
.L_poll_icf:                        ! --- poll Input Capture Flag ---
    mov.w   .L_reg_ftcsr, r0       ! r0 → FTCSR (0xFFFFFE11)
    mov.b @r0, r0                   ! read FTCSR byte
    extu.b r0, r0
    and #0x80, r0                   ! isolate ICF (bit 7)
    mov.w   .L_icf_bit, r3         ! r3 = 0x80
    cmp/eq r3, r0                   ! ICF set?
    bf      .L_loop_top             ! no → keep polling
    mov #0x0, r3
    mov.w   .L_reg_ftcsr, r2
    mov.b r3, @r2                   ! clear FTCSR (acknowledge ICF)
    mov.l   .L_ptr_callback, r0    ! r0 → callback pointer slot
    mov.l @r0, r0                   ! r0 = callback function (or NULL)
    tst r0, r0
    bt      .L_clear_callback       ! NULL → skip call
    mov.l   .L_ptr_callback_ct, r3 ! r3 → same slot via cache-through
    mov.l @r3, r2                   ! r2 = callback address (uncached)
    jsr @r2                         ! call the callback
    nop
.L_clear_callback:
    mov #0x0, r3
    mov.l   .L_ptr_callback, r2
    mov.l r3, @r2                   ! callback = NULL (one-shot)
.L_loop_top:
    bra     .L_poll_icf             ! infinite loop — never returns
    nop
.L_mask_sr_imask:
    .2byte  0xFF0F                  ! SR mask: clear I3..I0
.L_reg_tier:
    .2byte  0xFEE2                  ! → 0xFFFFFEE2 (FRT TIER word)
.L_reg_iprb:
    .2byte  0xFE60                  ! → 0xFFFFFE60 (IPRB)
.L_reg_tier_byte:
    .2byte  0xFE10                  ! → 0xFFFFFE10 (FRT TIER byte)
.L_reg_ftcsr:
    .2byte  0xFE11                  ! → 0xFFFFFE11 (FRT FTCSR)
.L_icf_bit:
    .2byte  0x0080                  ! ICF mask (bit 7)
    .2byte  0xFFFF                  ! alignment padding
.L_ptr_callback:
    .4byte  sym_06063574            ! callback pointer slot (WRAM)
.L_ptr_callback_ct:
    .4byte  sym_06063574 + 0x20000000  ! same slot, cache-through mirror

    .global sym_06034F78
sym_06034F78:                       ! bitfield_insert(r0=val, r1=width|pos, @r2=dest)
    mov.l r1, @-r15                 ! r1 packed: low byte=width, high byte=bit position
    mov.l r3, @-r15
    swap.b r1, r3                   ! r3 = bit position (high byte of r1)
    extu.b r1, r1                   ! r1 = field width (low byte)
    mov.l r4, @-r15
    extu.b r3, r3                   ! r3 = bit position (unsigned)
    mov.l r5, @-r15
    mov r1, r4                      ! r4 = width countdown
    mov.l r6, @-r15
    mov #0x0, r5                    ! r5 = value mask (initially 0)
    mov #-0x1, r6                   ! r6 = inv mask (initially 0xFFFFFFFF)
.L_build_val_mask:                  ! build width-bit mask in r5, inverse in r6
    shll r5                         ! shift mask pair left
    shll r6
    add #-0x1, r4                   ! width--
    add #0x1, r5                    ! set low bit of value mask
    cmp/pl r4
    bf      .L_shift_to_pos
    shll r5                         ! unrolled x2 for speed
    shll r6
    add #-0x1, r4
    add #0x1, r5
    cmp/pl r4
    bt      .L_build_val_mask
.L_shift_to_pos:
    and r5, r0                      ! r0 = val & width-mask (clamp input)
    mov #0x20, r4                   ! r4 = 32 - width - position
    sub r1, r4
    sub r3, r4
    mov r0, r5                      ! r5 = clamped value
    tst r4, r4
    bt      .L_merge_write          ! no shift needed
.L_shift_up_loop:                   ! shift value+mask to bit position
    shll r6
    shll r5
    add #-0x1, r4
    add #0x1, r6                    ! fill low bit of inverse mask
    cmp/pl r4
    bf      .L_merge_write
    shll r6                         ! unrolled x2
    shll r5
    add #-0x1, r4
    add #0x1, r6
    cmp/pl r4
    bt      .L_shift_up_loop
.L_merge_write:
    mov.l @r2, r4                   ! r4 = original word
    and r4, r6                      ! r6 = original & inverse_mask (clear field)
    or r6, r5                       ! r5 = cleared | shifted_value
    mov.l r5, @r2                   ! write back
    mov.l @r15+, r6
    mov.l @r15+, r5
    mov.l @r15+, r4
    mov.l @r15+, r3
    rts
    mov.l @r15+, r1

    .global sym_06034FE0
sym_06034FE0:                       ! frt_config(r0, r1) — configure FRT registers
    mov.l r2, @-r15
    mov.l r3, @-r15
    mov.w   .L_reg_frt_base, r3    ! r3 → 0xFFFFFF00 (FRT register base)
    mov #0x0, r2
    mov.l r0, @r3                   ! [base+0x00] = r0
    add #0x8, r3
    mov.l r2, @r3                   ! [base+0x08] = 0
    mov.l r1, @-r3                  ! [base+0x04] = r1 (pre-decrement: +8-4=+4)
    add #0x10, r3                   ! r3 → base+0x14
    mov.l @r3, r0                   ! return value = [base+0x14]
    mov.l @r15+, r3
    rts
    mov.l @r15+, r2
.L_reg_frt_base:
    .2byte  0xFF00                  ! → 0xFFFFFF00 (FRT register block)

    .global sym_06034FFC
sym_06034FFC:                       ! signed_div_32: r0 = r1 / r0 (32-bit signed)
    tst r0, r0                      ! divisor == 0?
    mov.l r2, @-r15
    bt      .L_sdiv_by_zero         ! yes → error handler
    mov.l r3, @-r15
    mov #0x0, r2
    div0s r2, r1                    ! set T flag from dividend sign
    subc r3, r3
    subc r2, r1
    div0s r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    div1 r0, r3
    rotcl r1
    addc r2, r1                     ! final correction
    mov r1, r0                      ! r0 = quotient
    mov.l @r15+, r3
    rts
    mov.l @r15+, r2
.L_sdiv_by_zero:                    ! --- divide by zero handler ---
    mov.l   .L_ptr_div_error, r1   ! r1 → error flag address
    mov.l   .L_div_error_code, r2  ! r2 = error code 0x44E
    mov #0x0, r0                    ! return 0
    mov.l r2, @r1                   ! store error code
    rts
    mov.l @r15+, r2
    .2byte  0x0009                  ! alignment pad (nop)
.L_ptr_div_error:
    .4byte  sym_060A246C            ! error flag variable (WRAM)
.L_div_error_code:
    .4byte  0x0000044E              ! error code: divide by zero

    .global sym_060350B0
sym_060350B0:                       ! unsigned_div_32: r0 = r1 % r0 (unsigned modulo)
    tst r0, r0                      ! divisor == 0?
    bt      .L_udiv_by_zero         ! yes → error
    mov.l r3, @-r15
    mov #0x0, r3                    ! r3 = running remainder
    mov.l r4, @-r15
    mov r0, r4                      ! r4 = divisor
    div0u                           ! clear T, Q, M for unsigned divide
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    rotcl r1
    div1 r4, r3
    bf      .L_udiv_add_remainder   ! T=0: need remainder correction
    mov r3, r0                      ! r0 = remainder (exact)
    mov.l @r15+, r4
    rts
    mov.l @r15+, r3
.L_udiv_add_remainder:
    add r3, r0                      ! r0 = corrected remainder
    mov.l @r15+, r4
    rts
    mov.l @r15+, r3
.L_udiv_by_zero:                    ! --- divide by zero handler ---
    mov.l r2, @-r15
    mov.l   .L_ptr_udiv_error, r1
    mov.l   .L_udiv_error_code, r2
    mov #0x0, r0                    ! return 0
    mov.l r2, @r1                   ! store error code
    rts
    mov.l @r15+, r2
    .2byte  0x0009                  ! alignment pad (nop)
.L_ptr_udiv_error:
    .4byte  sym_060A246C            ! error flag variable (WRAM)
.L_udiv_error_code:
    .4byte  0x0000044E              ! error code: divide by zero

    .global sym_06035168
sym_06035168:                       ! memcpy_long(r0=nbytes, r1=dst, r2=src)
    mov.l r3, @-r15                 ! jump-table unrolled for 0..16 longs
    mov #0x40, r3                   ! 0x40 = 64 bytes = 16 longs
    cmp/hs r0, r3                   ! size <= 64?
    bf      .L_memcpy_long_loop     ! no → generic loop
    mov.l   .L_ptr_jump_table, r3  ! yes → use jump table
    mov.l @(r0, r3), r3
    jmp @r3
    nop
.L_ptr_jump_table:
    .4byte  sym_060351C4            ! → unrolled copy entry points table
    .2byte  0x0009                  ! alignment pad (nop)
                                    ! --- unrolled copy: fall through copies 16→0 longs ---
    .global loc_0603517E
loc_0603517E:                       ! copy long 15 (offset 60)
    mov.l @(60, r2), r0
    mov.l r0, @(60, r1)

    .global loc_06035182
loc_06035182:
    mov.l @(56, r2), r0
    mov.l r0, @(56, r1)

    .global loc_06035186
loc_06035186:
    mov.l @(52, r2), r0
    mov.l r0, @(52, r1)

    .global loc_0603518A
loc_0603518A:
    mov.l @(48, r2), r0
    mov.l r0, @(48, r1)

    .global loc_0603518E
loc_0603518E:
    mov.l @(44, r2), r0
    mov.l r0, @(44, r1)

    .global loc_06035192
loc_06035192:
    mov.l @(40, r2), r0
    mov.l r0, @(40, r1)

    .global loc_06035196
loc_06035196:
    mov.l @(36, r2), r0
    mov.l r0, @(36, r1)

    .global loc_0603519A
loc_0603519A:
    mov.l @(32, r2), r0
    mov.l r0, @(32, r1)

    .global loc_0603519E
loc_0603519E:
    mov.l @(28, r2), r0
    mov.l r0, @(28, r1)

    .global loc_060351A2
loc_060351A2:
    mov.l @(24, r2), r0
    mov.l r0, @(24, r1)

    .global loc_060351A6
loc_060351A6:
    mov.l @(20, r2), r0
    mov.l r0, @(20, r1)

    .global loc_060351AA
loc_060351AA:
    mov.l @(16, r2), r0
    mov.l r0, @(16, r1)

    .global loc_060351AE
loc_060351AE:
    mov.l @(12, r2), r0
    mov.l r0, @(12, r1)

    .global loc_060351B2
loc_060351B2:
    mov.l @(8, r2), r0
    mov.l r0, @(8, r1)

    .global loc_060351B6
loc_060351B6:
    mov.l @(4, r2), r0
    mov.l r0, @(4, r1)

    .global loc_060351BA
loc_060351BA:
    mov.l @r2, r0
    mov.l r0, @r1

    .global loc_060351BE
loc_060351BE:
    rts
    mov.l @r15+, r3
    .2byte  0x0009

    .global sym_060351C4
sym_060351C4:
    .4byte  loc_060351BE
    .4byte  loc_060351BA
    .4byte  loc_060351B6
    .4byte  loc_060351B2
    .4byte  loc_060351AE
    .4byte  loc_060351AA
    .4byte  loc_060351A6
    .4byte  loc_060351A2
    .4byte  loc_0603519E
    .4byte  loc_0603519A
    .4byte  loc_06035196
    .4byte  loc_06035192
    .4byte  loc_0603518E
    .4byte  loc_0603518A
    .4byte  loc_06035186
    .4byte  loc_06035182
    .4byte  loc_0603517E
.L_memcpy_long_loop:                ! generic >64 byte path: copy 2 longs per iter
    mov.l r2, @-r15
    mov r2, r3                      ! r3 = end ptr
    add r0, r3
.L_copy_pair:
    mov.l @r2+, r0                  ! load long from src
    cmp/hs r2, r3                   ! past end?
    bf      .L_memcpy_long_done
    mov.l r0, @r1                   ! store to dst
    mov.l @r2+, r0                  ! 2nd long
    cmp/hs r2, r3
    bf      .L_memcpy_long_done
    mov.l r0, @(4, r1)
    bra     .L_copy_pair
    add #0x8, r1                    ! advance dst by 8
.L_memcpy_long_done:
    mov.l @r15+, r2
    rts
    mov.l @r15+, r3

    .global sym_06035228
sym_06035228:                       ! memcpy_byte(r0=nbytes, r1=dst, r2=src)
    mov.l r2, @-r15
    mov.l r3, @-r15
    mov.l r4, @-r15
    cmp/eq #0x0, r0                 ! zero bytes?
    bt      .L_bytecpy_done
    mov r2, r4                      ! r4 = src + nbytes (end ptr)
    add r0, r4
.L_copy_4bytes:                     ! unrolled: copy 4 bytes per iteration
    mov.b @r2+, r0
    mov.b r0, @r1
    cmp/hi r2, r4
    bf      .L_bytecpy_done
    mov.b @r2+, r0
    mov.b r0, @(1, r1)
    cmp/hi r2, r4
    bf      .L_bytecpy_done
    mov.b @r2+, r0
    mov.b r0, @(2, r1)
    cmp/hi r2, r4
    bf      .L_bytecpy_done
    mov.b @r2+, r0
    mov.b r0, @(3, r1)
    cmp/hi r2, r4
    add #0x4, r1
    bt      .L_copy_4bytes
.L_bytecpy_done:
    mov.l @r15+, r4
    mov.l @r15+, r3
    rts
    mov.l @r15+, r2

    .global sym_06035260
sym_06035260:
    mov.b @(r0, r0), r14
    .word 0x0A08 /* UNKNOWN */
    .4byte  loc_06040200
    .4byte  0x201E1C1A
    .4byte  0x18161412
    .4byte  0x3432302E
    .4byte  0x2C2A2826
    .4byte  0x403E3C3A
    .4byte  0x4856626C

    .global sym_06035280
sym_06035280:                       ! shift_left_n: r0 = r0 << r1
    mov.l r2, @-r15
    cmp/pz r1                       ! n < 0?
    bf/s    .L_shl_ret              ! yes → return unchanged
    mov #0x20, r2
    cmp/ge r2, r1                   ! n >= 32?
    bt      .L_shl_overflow         ! yes → result is 0
    mov.l   .L_ptr_shl_offsets, r2 ! byte offset table (indexed by n)
    add r1, r2
    mov.b @r2, r2                   ! r2 = jump offset for this n
    mov.l   .L_ptr_shl_base, r1   ! base of shll chain
    add r2, r1
    jmp @r1                         ! jump into unrolled shll chain
    nop
    .2byte  0x0009                  ! alignment pad (nop)
.L_ptr_shl_base:
    .4byte  sym_060352AA            ! → start of shll chain (max 7 shifts)
.L_ptr_shl_offsets:
    .4byte  sym_06035260            ! → byte offset table for dispatch
.L_shl_overflow:
    mov #0x0, r0                    ! n>=32 → result is zero
    rts
    mov.l @r15+, r2

    .global sym_060352AA
sym_060352AA:                       ! unrolled shll chain: 7 shifts + return
    shll r0                         ! r0 <<= 1 (x7, entered mid-chain)
    shll r0
    shll r0
    shll r0
    shll r0
    shll r0
    shll r0
.L_shl_ret:
    rts
    mov.l @r15+, r2
    .4byte  0x40004000
    .4byte  0x40004000
    .4byte  0x40004000
    .4byte  0x40004018
    .4byte  0x000B62F6
    .4byte  0x40004000
    .4byte  0x40004000
    .4byte  0x40004000
    .4byte  0x40004028
    .4byte  0x000B62F6
    .4byte  0x40004000
    .4byte  0x40004018
    .4byte  0x4028000B
    .4byte  0x62F6C90F
    .4byte  0x40054005
    .4byte  0x40054005
    .4byte  0x000B62F6
    .4byte  0xC9074005
    .4byte  0x40054005
    .4byte  0x000B62F6
    .4byte  0xC9034005
    .4byte  0x4005000B
    .4byte  0x62F6C901
    .4byte  0x4005000B
    .4byte  0x62F60000
    .4byte  0xFCFAF8F6
    .4byte  0xF4F2F0EE
    .4byte  0xECEAE8E6
    .4byte  0xE4E2E0DE
    .4byte  0xDCDAD8D6
    .4byte  0xD4D2D0CE

    .global sym_06035338
sym_06035338:                       ! shra dispatch offset table (byte data)
    mov.b @(r0, r0), r0
    mov.l r3, @-r2
    .word 0x4858 /* UNKNOWN */
    mov.l @r7, r6

    .global sym_06035340
sym_06035340:                       ! shift_right_arith_n: r0 = r0 >> r1 (arithmetic)
    mov.l r2, @-r15
    cmp/pz r1                       ! n < 0?
    bf/s    .L_shra_ret             ! yes → return unchanged
    mov #0x20, r2
    cmp/ge r2, r1                   ! n >= 32?
    bt      .L_shra_ge32            ! yes → sign-extend to 0 or -1
    mov r0, r2
    rotl r2                         ! T = sign bit of r0
    bf      .L_shra_small_check     ! positive → check small path
.L_shra_dispatch:                   ! negative value: dispatch via offset table
    mov.l   .L_ptr_shra_offsets, r2
    add #-0x18, r1                  ! adjust index (table starts at n=24)
    add r2, r1
    mov.b @r1, r2                   ! r2 = byte offset into shar chain
    mov.l   .L_ptr_shra_base, r1
    add r2, r1
    jmp @r1                         ! enter shar chain at correct point
    nop
.L_shra_small_check:
    mov #0x8, r2
    cmp/gt r2, r1                   ! n > 8?
    bf      .L_shra_dispatch        ! no → use offset dispatch
    mov.l   .L_fn_shra_large, r2   ! yes → call large-shift handler
    jmp @r2
    nop
    .2byte  0x0009                  ! alignment pad
.L_ptr_shra_offsets:
    .4byte  sym_06035338            ! → byte offset table for shar dispatch
.L_ptr_shra_base:
    .4byte  sym_060353BE            ! → base of shar chain
.L_fn_shra_large:
    .4byte  sym_06036068            ! → large shift handler (out-of-TU)
.L_shra_ge32:                       ! n >= 32: sign-extend to 0 or -1
    shll r0                         ! T = sign bit
    bt      .L_shra_neg_max         ! negative → return -1
    mov #0x0, r0                    ! positive → return 0
    rts
    mov.l @r15+, r2
.L_shra_neg_max:
    mov #-0x1, r0                   ! return 0xFFFFFFFF (-1)
    rts
    mov.l @r15+, r2
    .4byte  0x40214021
    .4byte  0x40214021
    .4byte  0x40214021
    .4byte  0x40214021
    .4byte  0x40214021
    .4byte  0x40214021
    .4byte  0x40214021
    .4byte  0x40214021
    .4byte  0x40214021
    .4byte  0x40214021
    .4byte  0x40214021
    .2byte  0x4021
.L_shra_ret:
    rts
    mov.l @r15+, r2

    .global sym_060353BE
sym_060353BE:                       ! sign_extend_byte: set high bits for negative shar
    swap.w r0, r1                   ! r1 = r0 with halfwords swapped
    swap.b r1, r0                   ! r0 = result with bytes rearranged
    mov #-0x80, r1                  ! r1 = 0xFFFFFF80
    or r1, r0                       ! set sign bits
    rts
    mov.l @r15+, r2
    .2byte  0x4004
    .4byte  0x40044004
    .4byte  0x40044004
    .4byte  0x40044004
    .4byte  0xE1C0201B
    .4byte  0x000B62F6
    .4byte  0x40044004
    .4byte  0x40044004
    .4byte  0x40044004
    .4byte  0xE1E0201B
    .4byte  0x000B62F6
    .4byte  0x40044004
    .4byte  0x40044004
    .4byte  0x4004E1F0
    .4byte  0x201B000B
    .4byte  0x62F64004
    .4byte  0x40044004
    .4byte  0x4004E1F8
    .4byte  0x201B000B
    .4byte  0x62F64004
    .4byte  0x40044004
    .4byte  0xE1FC201B
    .4byte  0x000B62F6
    .4byte  0x40044004
    .4byte  0xE1FE201B
    .4byte  0x000B62F6
    .4byte  0xE0FF000B
    .4byte  0x62F60000

    .global sym_06035438
sym_06035438:                       ! int_abs: r0 = |r4|
    cmp/pl r4                       ! r4 > 0?
    bf      .L_negate               ! no → negate
    bra     .L_abs_ret
    mov r4, r0                      ! r0 = r4 (positive or zero)
.L_negate:
    neg r4, r0                      ! r0 = -r4
.L_abs_ret:
    rts
    nop
    .2byte  0x0000
    .4byte  0x2F062F46
    .4byte  0x2F562F66
    .4byte  0x2F7654F6
    .4byte  0x55F756F8
    .4byte  0x57F9D0B4
    .4byte  0xA061260A

    .global sym_06035460
sym_06035460:                       ! fp_add_64: IEEE 754 double-precision add
    mov.l r0, @-r15                 ! args: (r4:r5=A_hi:lo, r6:r7=B_hi:lo) on stack
    mov.l r4, @-r15
    mov.l r5, @-r15
    mov.l r6, @-r15
    mov.l r7, @-r15
    mov.l @(24, r15), r6            ! r6:r7 = operand B (double)
    mov.l @(28, r15), r7
    mov.l @(32, r15), r4            ! r4:r5 = operand A (double)
    mov.l @(36, r15), r5
    mov.l   .L_fp_min, r0           ! r0 = 0x80000000 (sign bit)
    bra     .L_fadd_entry
    xor r0, r6                      ! flip sign of B (add = A + B, sub variant flips)
.L_exp_a_max:
    tst r4, r4
    bf      .L_result_zero
    tst r5, r5
    bf      .L_result_zero
    cmp/eq r3, r9
    bf      .L_nan_propagate
    tst r7, r7
    bf      .L_result_zero
    div0s r10, r11
    bf      .L_nan_propagate
.L_result_zero:
    mov #0x0, r10
    mov #0x0, r4
    bra     .L_fadd_epilog
    mov #0x8, r5
.L_nan_propagate:
    bra     .L_fadd_epilog
    nop
.L_exp_b_zero:
    tst r8, r8
    bf      .L_check_a_denorm
    tst r4, r4
    bf      .L_swap_and_norm
    tst r5, r5
    bf      .L_swap_and_norm
    tst r7, r7
    bf      .L_copy_b_to_result
    bra     .L_fadd_epilog
    and r11, r10
.L_check_a_denorm:
    tst r6, r6
    bf      .L_norm_b_start
    tst r7, r7
    bf      .L_norm_b_start
    bra     .L_shift_left_3
    nop
.L_swap_and_norm:
    tst r6, r6
    bf      .L_norm_a_start
    tst r7, r7
    bf      .L_norm_a_start
    bra     .L_shift_left_3
    nop
.L_copy_b_to_result:
    mov r6, r4
    mov r7, r5
    mov r9, r8
    mov r11, r10
.L_shift_left_3:
    shll r5
    rotcl r4
    shll r5
    rotcl r4
    shll r5
    bra     .L_fadd_epilog
    rotcl r4
.L_norm_a_start:
    mov.l   .L_fp_sixteen, r3
    shll r5
    rotcl r4
    cmp/ge r3, r4
    bt      .L_norm_b_start
.L_norm_a_loop:
    shll r5
    rotcl r4
    cmp/ge r3, r4
    bf/s    .L_norm_a_loop
    add #-0x1, r8
.L_norm_b_start:
    mov.l   .L_fp_sixteen, r3
    shll r7
    rotcl r6
    cmp/ge r3, r6
    bt      .L_align_mantissas
.L_norm_b_loop:
    shll r7
    rotcl r6
    cmp/ge r3, r6
    bf/s    .L_norm_b_loop
    add #-0x1, r9
.L_align_mantissas:
    bra     .L_shift_up_3
    nop
    .2byte  0xE800
    .4byte  0xE400A0DE
    .4byte  0xE5000009
    .4byte  0x2F062F46
    .4byte  0x2F562F66
    .4byte  0x2F7654F6
    .4byte  0x55F756F8
    .2byte  0x57F9
.L_fadd_entry:                      ! --- main entry: save regs, sort operands ---
    mov.l r2, @-r15
    mov.l r3, @-r15
    mov.l r8, @-r15
    mov.l r9, @-r15
    mov.l r10, @-r15
    mov.l r11, @-r15
    rotl r4                         ! rotate sign bit into T for magnitude compare
    rotl r6
    cmp/hs r6, r4                   ! |A| >= |B|? (unsigned compare after rotl)
    bt      .L_a_ge_b
    mov r4, r2                      ! swap A ↔ B so A has larger magnitude
    mov r6, r4
    mov r2, r6
    mov r5, r2
    mov r7, r5
    mov r2, r7
.L_a_ge_b:                          ! A >= B guaranteed from here
    rotr r4                         ! restore sign bits
    rotr r6
    mov.l   .L_exp_mask, r3        ! r3 = 0x7FF (11-bit exponent mask)
    mov.l   .L_mant_mask, r0       ! r0 = 0xFFFFF (20-bit mantissa mask)
    mov r4, r10                     ! r10 = A_hi (preserve original sign)
    mov r6, r11                     ! r11 = B_hi (preserve original sign)
    mov r4, r8                      ! extract exponent A
    shlr16 r8
    shlr2 r8
    shlr2 r8
    and r3, r8
    mov r6, r9
    shlr16 r9
    shlr2 r9
    shlr2 r9
    and r3, r9                      ! r9 = exponent B (11 bits)
    and r0, r4                      ! r4 = mantissa A (high 20 bits)
    and r0, r6                      ! r6 = mantissa B (high 20 bits)
    cmp/eq r3, r8                   ! exp A == 0x7FF? (NaN/Inf)
    bt      .L_exp_a_max
    tst r9, r9                      ! exp B == 0? (zero/denorm)
    bt      .L_exp_b_zero
.L_shift_up_3:                      ! shift mantissas left 3 bits for guard bits
    shll r5
    rotcl r4
    shll r5
    rotcl r4
    shll r5
    rotcl r4
    shll r7
    rotcl r6
    shll r7
    rotcl r6
    shll r7
    rotcl r6
    mov.l   .L_implicit_one, r0
    or r0, r4
    or r0, r6
    mov r8, r2
    sub r9, r2
    tst r2, r2
    bt      .L_add_sub_mantissa
    mov #0x3, r3
    cmp/ge r2, r3
    bt      .L_small_shift_right
    mov #0x36, r3
    cmp/gt r3, r2
    bt      .L_max_diff
    mov #0x20, r3
    cmp/gt r3, r2
    bf/s    .L_align_by_mul
    mov #0x1, r9
    sub r3, r2
    tst r7, r7
    bt      .L_merge_low
    or r9, r6
.L_merge_low:
    mov r6, r7
    mov #0x0, r6
.L_align_by_mul:
    sts.l mach, @-r15
    .word 0xC75F /* UNKNOWN */
    sts.l macl, @-r15
    shll2 r2
    add r2, r0
    mov.l @r0, r0
    dmulu.l r0, r7
    sts mach, r7
    sts macl, r2
    dmulu.l r0, r6
    sts mach, r6
    sts macl, r3
    lds.l @r15+, macl
    tst r2, r2
    lds.l @r15+, mach
    bt/s    .L_add_sub_mantissa
    or r3, r7
    bra     .L_add_sub_mantissa
    or r9, r7
.L_max_diff:
    mov #0x0, r6
    bra     .L_add_sub_mantissa
    mov #0x1, r7
.L_small_shift_right:
    shlr r6
    rotcr r7
    dt r2
    bf      .L_small_shift_right
.L_add_sub_mantissa:
    div0s r10, r11
    bt      .L_sub_path
    addc r7, r5
    addc r6, r4
    mov.l   .L_minit, r3
    cmp/gt r4, r3
    bt      .L_pack_result
    shlr r4
    rotcr r5
    .word 0x0229 /* UNKNOWN */
    or r2, r5
    add #0x1, r8
    mov.l   .L_exp_mask, r3
    cmp/eq r3, r8
    bf      .L_pack_result
    mov #0x0, r5
    bra     .L_fadd_epilog
    mov #0x0, r4
.L_sub_path:
    cmp/eq r4, r6
    bf      .L_sub_body
    cmp/eq r5, r7
    bt      .L_exact_zero
.L_sub_body:
    subc r7, r5
    subc r6, r4
    bf      .L_check_renorm
    clrt
    negc r5, r5
    negc r4, r4
    mov r11, r10
.L_check_renorm:
    tst r4, r4
    bf      .L_norm_xtrct
    mov r5, r4
    mov #0x0, r5
    add #-0x20, r8
.L_norm_xtrct:
    mov.l   .L_fp_neg_one, r3
    tst r4, r3
    bf      .L_check_overflow
    mov r5, r3
    xtrct r4, r3
    mov r3, r4
    shll16 r5
    add #-0x10, r8
.L_check_overflow:
    mov.l   .L_minit, r3
    cmp/hi r4, r3
    bt      .L_norm_left_check
.L_norm_right_loop:
    shlr r4
    rotcr r5
    cmp/hi r4, r3
    bt/s    .L_pack_result
    add #0x1, r8
    shlr r4
    rotcr r5
    cmp/hi r4, r3
    bt/s    .L_pack_result
    add #0x1, r8
    shlr r4
    rotcr r5
    cmp/hi r4, r3
    bt/s    .L_pack_result
    add #0x1, r8
    shlr r4
    rotcr r5
    cmp/hi r4, r3
    bt/s    .L_pack_result
    add #0x1, r8
    bra     .L_norm_right_loop
    nop
.L_norm_left_check:
    mov.l   .L_implicit_one, r3
    .4byte  0x34338913
    .4byte  0x45004424
    .4byte  0x34338D0F
    .4byte  0x78FF4500
    .4byte  0x44243433
    .4byte  0x8D0A78FF
    .4byte  0x45004424
    .4byte  0x34338D05
    .4byte  0x78FF4500
    .4byte  0x44243433
    .4byte  0x8FEC78FF
.L_pack_result:
    .4byte  0x48158905
    .4byte  0x688B7801
    .4byte  0x44014525
    .4byte  0x48108BFB
    .4byte  0x6053C804
    .4byte  0x890BC80B
    .4byte  0x8909E008
    .4byte  0x350EE000
    .4byte  0x340ED019
    .4byte  0x30478902
    .4byte  0x44014525
    .2byte  0x7801
.L_fadd_epilog:                     ! --- pack result: remove 3 guard bits ---
    shlr r4                         ! shift mantissa right 3 (undo guard bits)
    rotcr r5
    shlr r4
    rotcr r5
    shlr r4
    rotcr r5
    mov.l   .L_mant_mask, r0       ! mask to 20-bit mantissa field
    and r0, r4
    shll16 r8                       ! pack exponent into bits 20..30
    shll2 r8
    shll2 r8
    or r8, r4                       ! r4 = exponent | mantissa
    shll r4                         ! make room for sign bit
    shll r10                        ! T = original sign of result
    rotcr r4                        ! insert sign bit
    mov.l @r15+, r11               ! --- restore regs and return ---
    mov.l @r15+, r10
    mov.l @r15+, r9
    mov.l @r15+, r8
    mov.l @r15+, r3
    mov.l @r15+, r2
    mov.l @(20, r15), r6           ! r6 → output pointer
    mov.l r4, @r6                   ! store result_hi
    mov.l r5, @(4, r6)             ! store result_lo
    mov.l @r15+, r7
    mov.l @r15+, r6
    mov.l @r15+, r5
    mov.l @r15+, r4
    mov.l @r15+, r0
    rts
    add #0x14, r15                  ! deallocate stack frame
.L_exact_zero:                      ! A == B with opposite signs → exact zero
    mov #0x0, r10
    mov #0x0, r8
    mov #0x0, r4
    bra     .L_fadd_epilog
    mov #0x0, r5
    .2byte  0x0009
.L_exp_mask:
    .4byte  0x000007FF              ! IEEE 754 double exponent mask (11 bits)
.L_mant_mask:
    .4byte  0x000FFFFF              ! IEEE 754 double mantissa mask (high 20 bits)
.L_implicit_one:
    .4byte  0x00800000              ! implicit 1 bit (shifted left 3 for guard bits)
    .4byte  0x0000FFFF              ! 16-bit mask constant
.L_minit:
    .4byte  0x01000000              ! MINIT threshold / carry boundary
.L_fp_sixteen:
    .4byte  0x00100000              ! 0x100000 = implicit one at bit 20 (no guard bits)
.L_fp_min:
    .4byte  0x80000000              ! sign bit mask (MSB)
.L_fp_neg_one:
    .4byte  0xFFFF0000              ! upper 16 bits set (mask for normalization check)

    .global DAT_06035734
DAT_06035734:                       ! power-of-2 bitmask table (32 entries x2 sets)
    .word 0x0000 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    mov.b r0, @(0, r0)
    .word 0x0000 /* UNKNOWN */
    shll r0
    .word 0x0000 /* UNKNOWN */
    mov.b r0, @r0
    .word 0x0000 /* UNKNOWN */
    mov.l r0, @(0, r0)
    .word 0x0000 /* UNKNOWN */
    .word 0x0800 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0400 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0200 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0100 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0080 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0040 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0020 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0010 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    clrt
    .word 0x0000 /* UNKNOWN */
    mov.b r0, @(r0, r0)
    .word 0x0000 /* UNKNOWN */
    stc sr, r0
    .word 0x0000 /* UNKNOWN */
    .word 0x0001 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    mov.b r0, @(0, r0)
    .word 0x0000 /* UNKNOWN */
    shll r0
    .word 0x0000 /* UNKNOWN */
    mov.b r0, @r0
    .word 0x0000 /* UNKNOWN */
    mov.l r0, @(0, r0)
    .word 0x0000 /* UNKNOWN */
    .word 0x0800 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0400 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0200 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0100 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0080 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0040 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0020 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    .word 0x0010 /* UNKNOWN */
    .word 0x0000 /* UNKNOWN */
    clrt
    .word 0x0000 /* UNKNOWN */
    mov.b r0, @(r0, r0)
    .word 0x0000 /* UNKNOWN */
    stc sr, r0
    .word 0x0000 /* UNKNOWN */
    .word 0x0001 /* UNKNOWN */

    .global sym_060357B8
sym_060357B8:                       ! fp_to_int: double → 32-bit int (truncate)
    mov.l r1, @-r15                 ! input: double on stack, result in r0
    mov.l r2, @-r15
    mov.l r3, @-r15
    mov.l r4, @-r15
    mov.l r5, @-r15
    mov.l @(20, r15), r0            ! r0 = double_hi
    mov.l @(24, r15), r1            ! r1 = double_lo
    mov.l   .L_f2i_exp_mask, r4    ! r4 = 0x7FF
    mov.l   .L_f2i_mant_mask, r5   ! r5 = 0xFFFFF
    mov r0, r3                      ! r3 = hi (preserve for sign)
    mov r0, r2                      ! extract exponent
    shlr16 r2
    shlr2 r2
    shlr2 r2
    and r4, r2                      ! r2 = biased exponent (11 bits)
    and r5, r0                      ! r0 = mantissa (high 20 bits)
    mov.l   .L_f2i_exp_bias, r4   ! r4 = 0x3FF (IEEE 754 double bias)
    sub r4, r2                      ! r2 = unbiased exponent
    cmp/pz r2                       ! exp < 0? (|x| < 1.0)
    bf      .L_f2i_out_of_range     ! yes → return 0
    mov #0x53, r4                   ! max exponent = 83 (fits in 32-bit int)
    cmp/gt r4, r2
    bt      .L_f2i_out_of_range     ! overflow → return 0
    mov.l   .L_f2i_implicit_one, r4  ! set implicit 1 bit
    or r4, r0                       ! r0 = 1.mantissa (20+1 = 21 bits)
    add #-0x14, r2                  ! r2 = exp - 20 (shift amount)
    cmp/pz r2                       ! need to shift left?
    bf      .L_f2i_shift_down       ! no → shift right
    mov #0x20, r4
    cmp/ge r4, r2                   ! shift >= 32?
    bt      .L_f2i_shift_high       ! yes → use low word
    add #0x1, r2
.L_f2i_shift_up:                    ! shift mantissa left to form integer
    dt r2
    bt      .L_f2i_apply_sign
    shll r1                         ! shift 64-bit mantissa left
    bra     .L_f2i_shift_up
    rotcl r0
.L_f2i_shift_high:                  ! large exponent: use low word directly
    mov r1, r0
    add #-0x20, r2
    tst r2, r2
    bt      .L_f2i_apply_sign
.L_f2i_shift_extra:                 ! additional shifts for very large exponent
    dt r2
    bf/s    .L_f2i_shift_extra
    shll r0
    bra     .L_f2i_apply_sign
    nop
.L_f2i_shift_down:                  ! small exponent: shift right to truncate
    neg r2, r2
.L_f2i_shr_loop:
    dt r2
    bf/s    .L_f2i_shr_loop
    shlr r0                         ! logical shift right (unsigned truncation)
.L_f2i_apply_sign:
    shll r3                         ! T = sign bit of original double
    bf      .L_f2i_epilog
    neg r0, r0
.L_f2i_epilog:
    mov.l @r15+, r5
    mov.l @r15+, r4
    mov.l @r15+, r3
    mov.l @r15+, r2
    mov.l @r15+, r1
    rts
    add #0x8, r15
.L_f2i_out_of_range:                ! exponent out of int32 range → return 0
    bra     .L_f2i_epilog
    mov #0x0, r0
.L_f2i_exp_mask:
    .4byte  0x000007FF              ! 11-bit exponent mask
.L_f2i_mant_mask:
    .4byte  0x000FFFFF              ! 20-bit mantissa mask (high word)
.L_f2i_implicit_one:
    .4byte  0x00100000              ! implicit 1 at bit 20 (1.mantissa)
.L_f2i_exp_bias:
    .4byte  0x000003FF              ! IEEE 754 double bias (1023)

    .global sym_06035844
sym_06035844:                       ! fp_sub_64: IEEE 754 double-precision subtract
    mov.l r4, @-r15                 ! computes A - B as 64-bit IEEE 754 double
    mov.l r5, @-r15
    mov.l r6, @-r15
    mov.l r7, @-r15
    mov.l @(24, r15), r4            ! r4:r5 = operand A (double)
    mov.l @(28, r15), r5
    mov.l @(16, r15), r6            ! r6:r7 = operand B (double)
    mov.l @(20, r15), r7
    mov.l r8, @-r15
    mov.l r9, @-r15
    mov.l r10, @-r15
    mov.l r11, @-r15
    mov.l   .L_fsub_exp_field, r0  ! r0 = 0x7FF00000 (exp+sign field mask)
    mov r4, r10                     ! preserve originals for sign comparison
    mov r6, r11
    mov r4, r8
    and r0, r8
    mov r6, r9
    and r0, r9
    mov.l   .L_fsub_mant_field, r0
    and r0, r4
    and r0, r6
    mov.l   .L_fsub_exp_field, r0
    cmp/eq r0, r8
    bt      .L_fsub_a_is_special
.L_fsub_check_b_exp:
    cmp/eq r0, r9
    bt      .L_fsub_b_is_special
.L_fsub_check_a_zero:
    tst r8, r8
    bt      .L_fsub_a_exp_zero
.L_fsub_compute:                    ! main subtraction logic
    div0s r10, r11                  ! set T from sign comparison
    bt      .L_fsub_same_sign       ! same sign → special path
    cmp/pz r10                      ! A positive?
    bf      .L_fsub_neg_a           ! no → A is negative
    clrt                            ! A positive, B negative: compute A - B
    subc r5, r7                     ! 64-bit subtract: r10:r5 - r11:r7
    subc r10, r11
    bra     .L_fsub_epilog
    .word 0x0029 /* UNKNOWN */
.L_fsub_neg_a:                      ! A negative, B positive: compute B - A
    subc r7, r5
    subc r11, r10
    bra     .L_fsub_epilog
    .word 0x0029 /* UNKNOWN */
.L_fsub_same_sign:                  ! both same sign
    cmp/pz r10                      ! check sign of A
    .word 0x0029 /* UNKNOWN */
.L_fsub_epilog:                     ! --- restore regs and return ---
    mov.l @r15+, r11
    mov.l @r15+, r10
    mov.l @r15+, r9
    mov.l @r15+, r8
    mov.l @r15+, r7
    mov.l @r15+, r6
    mov.l @r15+, r5
    mov.l @r15+, r4
    rts
    add #0x10, r15                  ! deallocate stack frame
.L_fsub_a_is_special:               ! exp A = 0x7FF (NaN or Inf)
    tst r4, r4                      ! mantissa A != 0 → NaN
    bf      .L_fsub_return_zero
    tst r5, r5
    bf      .L_fsub_return_zero
    bra     .L_fsub_check_b_exp     ! mantissa = 0 → Inf, check B
    nop
.L_fsub_b_is_special:               ! exp B = 0x7FF (NaN or Inf)
    tst r6, r6                      ! mantissa B != 0 → NaN
    bf      .L_fsub_return_zero
    tst r7, r7
    bf      .L_fsub_return_zero
    bra     .L_fsub_check_a_zero    ! mantissa = 0 → Inf, check A
    nop
.L_fsub_a_exp_zero:                 ! exp A = 0 — check if both are zero
    tst r9, r9                      ! exp B != 0 → not both zero
    bf      .L_fsub_compute
    tst r4, r4                      ! check all mantissa/exp bits
    bf      .L_fsub_compute
    tst r5, r5
    bf      .L_fsub_compute
    tst r6, r6
    bf      .L_fsub_compute
    tst r7, r7
    bf      .L_fsub_compute
    bra     .L_fsub_epilog          ! both exactly zero → return 0
    mov #0x0, r0
.L_fsub_return_zero:                ! NaN/invalid → return 0
    bra     .L_fsub_epilog
    mov #0x0, r0
.L_fsub_exp_field:
    .4byte  0x7FF00000              ! exponent + sign field mask
.L_fsub_mant_field:
    .4byte  0x000FFFFF              ! mantissa field mask (high 20 bits)

    .global sym_060358EC
sym_060358EC:                       ! int_to_fp: 32-bit int → IEEE 754 double
    mov.l r1, @-r15                 ! input: r0 = int32, output: double at @stack
    mov.l r2, @-r15
    mov.l r3, @-r15
    tst r0, r0                      ! input == 0?
    bt      .L_i2f_zero_input       ! yes → return +0.0
    mov #0x0, r3                    ! r3 = sign flag (0 = positive)
    cmp/pz r0                       ! input >= 0?
    bt      .L_i2f_positive
    mov #0x1, r3                    ! negative: set sign flag
    neg r0, r0                      ! make positive for normalization
.L_i2f_positive:
    mov.l   .L_i2f_exp_init, r1   ! r1 = 0x41F (1023 + 31 = max biased exp)
.L_i2f_norm_loop:                   ! find leading 1 bit: shift left until T=1
    shll r0                         ! shift out leading zeros
    bf/s    .L_i2f_norm_loop        ! T=0 → still leading zeros
    add #-0x1, r1                   ! decrement exponent for each zero
    mov r0, r2                      ! r2 = low bits of mantissa (for lo word)
    shll16 r2                       ! shift to form double_lo
    shll2 r2
    shll2 r2
    shlr8 r0                        ! shift mantissa into position for double_hi
    shlr2 r0
    shlr2 r0
    shll16 r1                       ! pack exponent into bits 20..30
    shll2 r1
    shll2 r1
    or r1, r0                       ! r0 = exponent | mantissa_hi
    shll r0                         ! make room for sign bit
    shlr r3                         ! T = sign flag
    rotcr r0                        ! insert sign bit as MSB
.L_i2f_store:                       ! store result double to output pointer
    mov.l @(12, r15), r1           ! r1 → output address (passed on stack)
    mov.l r0, @r1                   ! store double_hi
    mov.l r2, @(4, r1)             ! store double_lo
    mov.l @r15+, r3
    mov.l @r15+, r2
    mov.l @r15+, r1
    rts
    add #0x4, r15                   ! deallocate stack
.L_i2f_zero_input:                  ! input is zero → return +0.0 double
    mov #0x0, r2                    ! lo = 0
    bra     .L_i2f_store
    mov #0x0, r0                    ! hi = 0
    .2byte  0x0009                  ! alignment pad
.L_i2f_exp_init:
    .4byte  0x0000041F              ! bias + 31 = 1023 + 31 = 1054 (0x41E+1)
    .4byte  0x24488B4A
    .4byte  0x25588B48
    .4byte  0x39308907
    .4byte  0x29988B40
    .4byte  0x26688B3E
    .4byte  0x27788B3C
    .4byte  0xA03F0009
    .4byte  0x26688B3C
    .4byte  0x27788B3A
    .4byte  0xA0350009
    .4byte  0x26688B36
    .4byte  0x27788B34
    .4byte  0x28888B2E
    .4byte  0x24488B2C
    .4byte  0x25588B2A
    .4byte  0xA02D0009
    .4byte  0x24488B03
    .4byte  0x25588B01
    .4byte  0xA01E0009
    .4byte  0xD0664500
    .4byte  0x44243403
    .4byte  0x89044500
    .4byte  0x44243403
    .4byte  0x8FFB78FF
    .4byte  0xA04B0009
    .4byte  0x26688B03
    .4byte  0x27788B01
    .4byte  0xA00C0009
    .4byte  0xD05D4700
    .4byte  0x46243603
    .4byte  0x89044700
    .4byte  0x46243603
    .4byte  0x8FFB79FF
    .4byte  0xA03B0009
    .4byte  0x4A000129
    .4byte  0xE000A091
    .4byte  0x4105D853
    .4byte  0xE100A07E
    .4byte  0xE000EA00
    .4byte  0xD850E100
    .4byte  0xA079E008

    .global sym_060359E4
sym_060359E4:                       ! fp_mul_64: IEEE 754 double-precision multiply (partial)
    mov.l r0, @-r15                 ! args: doubles on stack, result to output ptr
    mov.l r1, @-r15
    mov.l r4, @-r15
    mov.l r5, @-r15
    mov.l r6, @-r15
    mov.l r7, @-r15
    mov.l @(28, r15), r4            ! r4:r5 = operand A (double)
    mov.l @(32, r15), r5
    mov.l @(36, r15), r6            ! r6:r7 = operand B (double)
    mov.l @(40, r15), r7
    mov.l r2, @-r15                 ! save all callee-saved regs
    mov.l r3, @-r15
    mov.l r8, @-r15
    mov.l r9, @-r15
    mov.l r10, @-r15
    mov.l r11, @-r15
    mov.l r12, @-r15                ! (continues beyond TU boundary)
    mov.l r13, @-r15
